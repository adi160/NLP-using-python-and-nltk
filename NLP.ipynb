{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adi160/NLP-using-python-and-nltk/blob/master/NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "I9Ejv3SN02wC",
        "colab_type": "code",
        "outputId": "a4ec5dc8-3bdd-46b5-ec93-1887f3e9650d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "cell_type": "code",
      "source": [
        "from nltk import sent_tokenize,word_tokenize\n",
        "\n",
        "example_text=\"The Natural Language Toolkit,or more commonly NLTK,is a suite of libraries and programs for symbolic and statistical natural language processing (NLP) for English written in the Python programming language. It was developed by Steven Bird and Edward Loper in the Department of Computer and Information Science at the University of Pennsylvania. NLTK includes graphical demonstrations and sample data. It is accompanied by a book that explains the underlying concepts behind the language processing tasks supported by the toolkit,plus a cookbook written by Mr. Aditya.\"\n",
        "\n",
        "for i in sent_tokenize(example_text):\n",
        "  print(i)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Natural Language Toolkit,or more commonly NLTK,is a suite of libraries and programs for symbolic and statistical natural language processing (NLP) for English written in the Python programming language.\n",
            "It was developed by Steven Bird and Edward Loper in the Department of Computer and Information Science at the University of Pennsylvania.\n",
            "NLTK includes graphical demonstrations and sample data.\n",
            "It is accompanied by a book that explains the underlying concepts behind the language processing tasks supported by the toolkit,plus a cookbook written by Mr. Aditya.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PwFYFXCZ4rQH",
        "colab_type": "code",
        "outputId": "c15178e4-b5a8-45b9-8f14-f329a93eb6b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1649
        }
      },
      "cell_type": "code",
      "source": [
        "for i in word_tokenize(example_text):\n",
        "  print(i)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The\n",
            "Natural\n",
            "Language\n",
            "Toolkit\n",
            ",\n",
            "or\n",
            "more\n",
            "commonly\n",
            "NLTK\n",
            ",\n",
            "is\n",
            "a\n",
            "suite\n",
            "of\n",
            "libraries\n",
            "and\n",
            "programs\n",
            "for\n",
            "symbolic\n",
            "and\n",
            "statistical\n",
            "natural\n",
            "language\n",
            "processing\n",
            "(\n",
            "NLP\n",
            ")\n",
            "for\n",
            "English\n",
            "written\n",
            "in\n",
            "the\n",
            "Python\n",
            "programming\n",
            "language\n",
            ".\n",
            "It\n",
            "was\n",
            "developed\n",
            "by\n",
            "Steven\n",
            "Bird\n",
            "and\n",
            "Edward\n",
            "Loper\n",
            "in\n",
            "the\n",
            "Department\n",
            "of\n",
            "Computer\n",
            "and\n",
            "Information\n",
            "Science\n",
            "at\n",
            "the\n",
            "University\n",
            "of\n",
            "Pennsylvania\n",
            ".\n",
            "NLTK\n",
            "includes\n",
            "graphical\n",
            "demonstrations\n",
            "and\n",
            "sample\n",
            "data\n",
            ".\n",
            "It\n",
            "is\n",
            "accompanied\n",
            "by\n",
            "a\n",
            "book\n",
            "that\n",
            "explains\n",
            "the\n",
            "underlying\n",
            "concepts\n",
            "behind\n",
            "the\n",
            "language\n",
            "processing\n",
            "tasks\n",
            "supported\n",
            "by\n",
            "the\n",
            "toolkit\n",
            ",\n",
            "plus\n",
            "a\n",
            "cookbook\n",
            "written\n",
            "by\n",
            "Mr.\n",
            "Aditya\n",
            ".\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RhrAgXyW4uT0",
        "colab_type": "code",
        "outputId": "46e29170-2c35-4ad7-e7ff-d19feaaf02ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "\n",
        "print(stop_words)\n",
        "\n",
        "words = word_tokenize(example_text)\n",
        "\n",
        "filtered_sentence=[]\n",
        "\n",
        "for w in words:\n",
        "  if w not in stop_words:\n",
        "    filtered_sentence.append(w)\n",
        "    \n",
        "print(filtered_sentence)    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'because', 'did', 'after', \"you've\", 'yourselves', 'few', 'our', 'hers', 'been', 'just', 'before', 'we', \"you'll\", 'such', 'hadn', \"isn't\", 'their', 'mustn', 'will', 'against', 'these', 'are', 'through', 'if', 'those', 're', 'him', 'into', 'herself', 'for', 'won', 'had', 'between', 'shan', \"mightn't\", 'isn', 'himself', 'any', 'to', \"wouldn't\", 'shouldn', 'themselves', 'there', \"shan't\", 'his', 'y', 'it', 's', 'too', 'yourself', 'whom', 'your', 'mightn', 'or', 'my', 'other', 'ours', 'with', 'from', 'on', 've', 'by', 'not', \"won't\", \"wasn't\", 'he', 'an', \"weren't\", 'its', 'most', 'is', 'further', \"you'd\", 'o', 'some', 'they', 'the', \"didn't\", 'but', \"couldn't\", 'each', 'why', 'doesn', 'that', 'in', \"should've\", 'wasn', 'again', 'out', 'myself', 'below', 'haven', 'aren', 'couldn', 'them', 'up', 'under', 'should', 'can', 'now', \"don't\", 'during', 'nor', 'very', 'has', 'over', 'both', 'then', 'of', \"hasn't\", 'itself', 'all', \"you're\", \"hadn't\", 'having', 'and', 'when', 'than', \"aren't\", 'what', 'who', 'same', 'am', 'wouldn', 'about', 'own', 'have', 'me', 'ma', \"that'll\", 'a', 'be', 'ourselves', 'i', 'she', 'down', 'until', \"shouldn't\", 'so', 'does', 'm', 'doing', 'being', 'needn', 'd', 'll', 'above', 't', 'only', 'more', 'theirs', \"mustn't\", 'this', 'once', 'at', \"she's\", 'didn', 'as', 'were', 'ain', 'her', 'don', \"needn't\", 'here', 'weren', \"it's\", 'you', 'yours', 'where', 'no', 'was', 'do', 'off', \"haven't\", 'which', 'while', 'how', \"doesn't\", 'hasn'}\n",
            "['The', 'Natural', 'Language', 'Toolkit', ',', 'commonly', 'NLTK', ',', 'suite', 'libraries', 'programs', 'symbolic', 'statistical', 'natural', 'language', 'processing', '(', 'NLP', ')', 'English', 'written', 'Python', 'programming', 'language', '.', 'It', 'developed', 'Steven', 'Bird', 'Edward', 'Loper', 'Department', 'Computer', 'Information', 'Science', 'University', 'Pennsylvania', '.', 'NLTK', 'includes', 'graphical', 'demonstrations', 'sample', 'data', '.', 'It', 'accompanied', 'book', 'explains', 'underlying', 'concepts', 'behind', 'language', 'processing', 'tasks', 'supported', 'toolkit', ',', 'plus', 'cookbook', 'written', 'Mr.', 'Aditya', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}